{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2b5430-6712-48da-80ad-f38c7205d756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:16:05.628145200Z",
     "start_time": "2025-03-19T16:16:02.139968400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import utils\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "import models\n",
    "import training\n",
    "\n",
    "NUM_CLASSES = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b46739",
   "metadata": {},
   "source": [
    "### Self-Supervised MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940dcbef-d9c5-44a6-b8ba-c37f1a951589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:21:02.481667300Z",
     "start_time": "2025-03-19T13:21:02.374570Z"
    }
   },
   "outputs": [],
   "source": [
    "# MNIST TRAINING\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=False, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "dl_val = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdbcbd90-e96f-4803-95c0-73aabbe5c30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:21:04.230257Z",
     "start_time": "2025-03-19T13:21:02.470657500Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m checkpoints_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_mnist.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      6\u001B[0m trainer \u001B[38;5;241m=\u001B[39m training\u001B[38;5;241m.\u001B[39mSelfSupervisedTrainer(model, dl_train, dl_val, loss_fn, optimizer, device)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheckpoints_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Final_Project_Deep_Learning\\project\\training.py:28\u001B[0m, in \u001B[0;36mSelfSupervisedTrainer.train\u001B[1;34m(self, num_epochs, checkpoints)\u001B[0m\n\u001B[0;32m     26\u001B[0m reconstructed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(images)\n\u001B[0;32m     27\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn(reconstructed, images)\n\u001B[1;32m---> 28\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     31\u001B[0m total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deep_project\\lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deep_project\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deep_project\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    824\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    825\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = models.SelfSupervised_MNIST(latent_dim=128)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "checkpoints_path = \"encoder_mnist.pth\"\n",
    "trainer = training.SelfSupervisedTrainer(model, dl_train, dl_val, loss_fn, optimizer, device)\n",
    "trainer.train(num_epochs=10, checkpoints=checkpoints_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17dc9af",
   "metadata": {},
   "source": [
    "### Self-Supervised MNIST: Reconstruction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9517bf-64ba-4fcd-8b6e-667360d89150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:21:04.238264200Z",
     "start_time": "2025-03-19T13:21:04.231257600Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(test_dataset), 5, replace=False)\n",
    "\n",
    "utils.showReconstructions(model, test_dataset, device, indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498be416",
   "metadata": {},
   "source": [
    "### Self-Supervised MNIST: Linear Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443daaa-c696-48b2-9501-d77d5fcc3783",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.232258600Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.displayInterpolation(model, test_dataset, device, indices[0], indices[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298efff4",
   "metadata": {},
   "source": [
    "### Self-Supervised MNIST: t-SNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac06c7e-c2f5-4f56-8d57-a52f774cfdc4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.233259500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "utils.plot_tsne(model.encoder, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f1fa9-8c0e-43be-aaad-26bfc3ca0749",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.234260100Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.display_tsne()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c2fc0-5547-4a7a-a3c3-a3c24d6d907d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.235261Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = models.SelfSupervised_MNIST(latent_dim=128).encoder\n",
    "encoder.load_state_dict(torch.load(\"encoder_mnist.pth\"))\n",
    "encoder.to(device)\n",
    "encoder.eval()  \n",
    "\n",
    "classifier = models.Classifier(latent_dim=128, num_classes=10).to(device)\n",
    "fn_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "checkpoints_path = \"classifier_mnist.pth\"\n",
    "trainer = training.ClassifierTrainer(classifier, encoder, dl_train, dl_val, fn_loss, optimizer, device)\n",
    "trainer.train(num_epochs=10, checkpoints=checkpoints_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb959e2a",
   "metadata": {},
   "source": [
    "### Classification-Guided MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670db112-6e68-47e2-8baf-56d8787b3982",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.236262100Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.ClassificationGuided_MNIST().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "trainer = training.ClassificationGuidedTrainer(model,  dl_train, dl_val, dl_test, loss_fn, optimizer, device)\n",
    "checkpoints_path = \"guided_mnist.pth\"\n",
    "\n",
    "trainer.train(num_epochs=10, checkpoints=checkpoints_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8754f57",
   "metadata": {},
   "source": [
    "### Classification-Guided MNIST: t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83db96a-6ecc-4430-abbf-ba7381543bd4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.237262800Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_tsne(model.encoder, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b3136-5686-433d-8acd-e45295ca461c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.237262800Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.display_tsne()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd753636",
   "metadata": {},
   "source": [
    "### Self-Supervised CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c4a86-a1e7-4d7a-8e64-73511267aefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:21:04.241266600Z",
     "start_time": "2025-03-19T13:21:04.238264200Z"
    }
   },
   "outputs": [],
   "source": [
    "# CIFAR10 TRAINING\n",
    "'''\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "'''\n",
    "#transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])])\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=False)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=False)\n",
    "\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "dl_val = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0a43a-a36a-4cfb-9e60-3369418c9258",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.239264900Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.SelfSupervised_CIFAR10(latent_dim=128)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "checkpoints_path = \"encoder_cifar10.pth\"\n",
    "trainer = training.SelfSupervisedTrainer(model, dl_train, dl_val, loss_fn, optimizer, device, scheduler)\n",
    "trainer.train(num_epochs=20, checkpoints=checkpoints_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34ef3e",
   "metadata": {},
   "source": [
    "### Self-Supervised CIFAR10: Reconstruction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494adc89-ee22-4639-8984-1df8a0941799",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.240265700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "indices = np.random.choice(len(test_dataset), 5, replace=False)\n",
    "\n",
    "utils.showReconstructions(model, test_dataset, device, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a2bab-23fc-4fee-94f8-23da25595e19",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.241266600Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = models.SelfSupervised_CIFAR10(latent_dim=128).encoder\n",
    "encoder.load_state_dict(torch.load(\"encoder_cifar10.pth\"))\n",
    "encoder.to(device)\n",
    "encoder.eval()  \n",
    "\n",
    "classifier = models.Classifier(latent_dim=128, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "checkpoints_path = \"classifier_cifar10.pth\"\n",
    "trainer = training.ClassifierTrainer(classifier, encoder, dl_train, dl_test, criterion, optimizer, device, scheduler)\n",
    "trainer.train(num_epochs=30, checkpoints=checkpoints_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d2975",
   "metadata": {},
   "source": [
    "### Self-Supervised CIFAR10: t-SNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d57bb-dd68-415e-b58d-613f8ee0c4e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:21:04.248273300Z",
     "start_time": "2025-03-19T13:21:04.242267700Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_tsne(model.encoder, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e88a1-9d73-49e4-937e-94514adb9ad2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.242267700Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.display_tsne()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68436b47",
   "metadata": {},
   "source": [
    "### Classification-Guided CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929115d-651a-4ff1-a131-5d42e78e892e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.243268600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = models.ClassificationGuided_CIFAR10().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "trainer = training.ClassificationGuidedTrainer(model,  dl_train, dl_val, dl_test, loss_fn, optimizer, device)\n",
    "checkpoints_path = \"guided_cifar10.pth\"\n",
    "\n",
    "trainer.train(num_epochs=50, checkpoints=checkpoints_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd30c8",
   "metadata": {},
   "source": [
    "### Classification-Guided CIFAR10: t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc5cd5-546e-4a80-b783-3cd962b434c2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.244269500Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_tsne(model.encoder, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b8276-ce9a-4402-b401-5e0393a40a23",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:21:04.245270300Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.display_tsne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b20321e7e961253b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T17:09:31.188456500Z",
     "start_time": "2025-03-19T17:09:29.960340400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root=\"/datasets/cv_datasets/data\", train=True, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"/datasets/cv_datasets/data\", train=False, download=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "clr_lr = 0.05\n",
    "class_lr = 0.001\n",
    "\n",
    "T = 0.1\n",
    "batch_size = 1024"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f32a68916d951bc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481d0b60-978c-41a6-aea5-5d026e320bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T17:09:31.869075200Z",
     "start_time": "2025-03-19T17:09:31.824034100Z"
    }
   },
   "outputs": [],
   "source": [
    "from ConstructiveNet import *\n",
    "from models import simCLR_CIFAR10\n",
    "from training import simCLRTrainer\n",
    "from utils import create_data_sets\n",
    "\n",
    "clr_encoder = Encoder() \n",
    "clr_projection_head = ProjectionHead()\n",
    "clr_classifier = LinearClassifier()\n",
    "model = simCLR_CIFAR10(clr_encoder, clr_projection_head, clr_classifier).to(device)\n",
    "loss_fn = NTXentLoss\n",
    "class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=clr_lr)\n",
    "class_optimizer = optim.Adam(model.classifier_head.parameters(), lr=class_lr)\n",
    "\n",
    "trainer = simCLRTrainer(epochs=epochs, model=model, optimizer=optimizer, loss_fn=loss_fn, temperature=T, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51678cd694075b1b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T17:13:34.388850400Z",
     "start_time": "2025-03-19T17:10:15.170206500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 45000\n",
      "Validation set size: 5000\n",
      "Test set size: 10000\n",
      "------Epoch [1/20]:--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.0702  |  Validation Loss: 0.6773\n",
      "------Epoch [2/20]:--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.0424  |  Validation Loss: 0.6723\n",
      "------Epoch [3/20]:--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m test_ds \u001B[38;5;241m=\u001B[39m TestDataset(test_dataset, transform\u001B[38;5;241m=\u001B[39msimclr_transform)\n\u001B[0;32m      6\u001B[0m dl_train, dl_valid, dl_test \u001B[38;5;241m=\u001B[39m create_data_sets(train_ds, test_ds, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m1024\u001B[39m, simclr_transform)\n\u001B[1;32m----> 8\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdl_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_valid\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Final_Project_Deep_Learning\\project\\training.py:287\u001B[0m, in \u001B[0;36mfit\u001B[1;34m(self, train_loader, val_loader)\u001B[0m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_loader, val_loader):\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs):\n\u001B[1;32m--> 287\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m------Epoch [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]:--------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    288\u001B[0m         train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_epoch(train_loader)\n\u001B[0;32m    289\u001B[0m         val_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate_epoch(val_loader)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Final_Project_Deep_Learning\\project\\training.py:219\u001B[0m, in \u001B[0;36msimCLRTrainer.train_epoch\u001B[1;34m(self, train_loader)\u001B[0m\n\u001B[0;32m    217\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(x)\n\u001B[0;32m    218\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn(z, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtemperature)\n\u001B[1;32m--> 219\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    222\u001B[0m epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m x1\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deep_project\\lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deep_project\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deep_project\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    824\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    825\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "simclr_transform = get_simclr_augmentation(input_size=32)\n",
    "\n",
    "train_ds = SimCLRDataset(train_dataset, transform=simclr_transform)\n",
    "test_ds = TestDataset(test_dataset, transform=simclr_transform)\n",
    "\n",
    "dl_train, dl_valid, dl_test = create_data_sets(train_ds, test_ds, 0.1, batch_size, simclr_transform)\n",
    "\n",
    "trainer.fit(dl_train, dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  30.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for param in trainer.model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_ds_classifier = TestDataset(train_dataset, classifier_transform)\n",
    "train_loader_classifier = torch.utils.data.DataLoader(train_ds_classifier, batch_size=256)\n",
    "\n",
    "trainer.train_classifier(train_loader_classifier, class_optimizer, class_loss_fn)\n",
    "\n",
    "trainer.test(dl_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T16:49:30.344781900Z",
     "start_time": "2025-03-19T16:44:25.283502800Z"
    }
   },
   "id": "a9c8814d26be2bf5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "33f596abf667b3a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
