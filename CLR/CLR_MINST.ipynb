{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "582590096dbb0597",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-20T00:22:15.531891800Z",
          "start_time": "2025-03-20T00:22:12.983071600Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "582590096dbb0597"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from train import *\n",
        "import utils\n",
        "from model import CLR\n",
        "\n",
        "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-20T00:22:16.759007100Z",
          "start_time": "2025-03-20T00:22:16.754002300Z"
        },
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "feature_dim = 128\n",
        "batch_size = 1024\n",
        "epochs = 20\n",
        "\n",
        "# CLR train\n",
        "CLR_lr = 0.6\n",
        "CLR_min_lr = 1e-3\n",
        "CLR_momentum = 0.9\n",
        "CLR_wd = 1e-6\n",
        "temperature = 0.4\n",
        "\n",
        "# Classify train\n",
        "Class_lr = 1e-3\n",
        "Class_wd = 1e-4\n",
        "\n",
        "dataset = \"MINIST\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "314e53d87154dd9a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-20T00:22:17.496677200Z",
          "start_time": "2025-03-20T00:22:17.480662700Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "314e53d87154dd9a",
        "outputId": "33bca6c0-f42d-4254-8be7-e3cfc26c9e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4bb6999b46c39123",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-20T00:22:19.734214600Z",
          "start_time": "2025-03-20T00:22:18.242354800Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4bb6999b46c39123"
      },
      "outputs": [],
      "source": [
        "if dataset == \"CIFAR10\":\n",
        "    in_ch = 3\n",
        "    CLR_train_data = utils.CIFAR10Pair(root='/datasets/cv_datasets/data', train=True,\n",
        "                                       transform=utils.CIFAR10_train_transform, download=True)\n",
        "    Class_train_data = utils.CIFAR10(root='/datasets/cv_datasets/data', train=True, transform=utils.CIFAR10_test_transform,\n",
        "                                     download=True)\n",
        "    test_data = utils.CIFAR10(root='/datasets/cv_datasets/data', train=False, transform=utils.CIFAR10_test_transform,\n",
        "                              download=True)\n",
        "else:\n",
        "    in_ch = 1\n",
        "    CLR_train_data = utils.MNISTPair(root='./data', train=True,\n",
        "                                     transform=utils.MNIST_train_transform, download=True)\n",
        "    Class_train_data = utils.MNIST(root='./data', train=True, transform=utils.MNIST_test_transform,\n",
        "                                   download=True)\n",
        "    test_data = utils.MNIST(root='./data', train=False, transform=utils.MNIST_test_transform,\n",
        "                            download=True)\n",
        "CLR_train_loader = DataLoader(CLR_train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True,\n",
        "                              drop_last=True)\n",
        "Class_train_loader = DataLoader(Class_train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9be5577121678a19",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-20T00:22:20.389810300Z",
          "start_time": "2025-03-20T00:22:20.367790300Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9be5577121678a19"
      },
      "outputs": [],
      "source": [
        "model = CLR(in_ch, feature_dim).to(device)\n",
        "CLR_optimizer = torch.optim.SGD(model.parameters(), CLR_lr, momentum=CLR_momentum, weight_decay=CLR_wd)\n",
        "CLR_loss_fn = utils.NTXentLoss\n",
        "Class_optimizer = torch.optim.SGD(model.classifier.parameters(), lr=Class_lr, momentum=0.9, weight_decay=Class_wd)\n",
        "Class_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "warmup = LinearLR(CLR_optimizer, start_factor=1e-4, end_factor=1.0, total_iters=5 * len(CLR_train_loader))\n",
        "\n",
        "cosine = CosineAnnealingLR(CLR_optimizer, T_max=(epochs - 5) * len(CLR_train_loader), eta_min=CLR_min_lr)\n",
        "\n",
        "scheduler = SequentialLR(CLR_optimizer, schedulers=[warmup, cosine], milestones=[5 * len(CLR_train_loader)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aaf2ca79791d6540",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-20T00:22:43.600249900Z",
          "start_time": "2025-03-20T00:22:21.159509500Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaf2ca79791d6540",
        "outputId": "5bde1695-6dae-40e0-f2c9-f265dd80b168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Train------------\n",
            "Epoch: 1, Loss: 6.276703916746994\n",
            "Epoch: 2, Loss: 5.674489473474437\n",
            "Epoch: 3, Loss: 5.40928107294543\n",
            "Epoch: 4, Loss: 5.259128586999301\n",
            "Epoch: 5, Loss: 5.131481326859573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Loss: 5.040282117909398\n",
            "Epoch: 7, Loss: 4.971941446435863\n",
            "Epoch: 8, Loss: 4.936141696469537\n",
            "Epoch: 9, Loss: 4.903209982247188\n",
            "Epoch: 10, Loss: 4.87939661124657\n",
            "Epoch: 11, Loss: 4.859683513641357\n",
            "Epoch: 12, Loss: 4.848694308050748\n",
            "Epoch: 13, Loss: 4.830592821384299\n",
            "Epoch: 14, Loss: 4.817731577774574\n",
            "Epoch: 15, Loss: 4.809844715841885\n",
            "Epoch: 16, Loss: 4.803453675631819\n",
            "Epoch: 17, Loss: 4.798894725996872\n",
            "Epoch: 18, Loss: 4.787950910370926\n",
            "Epoch: 19, Loss: 4.7876068230332995\n",
            "Epoch: 20, Loss: 4.785810972082204\n"
          ]
        }
      ],
      "source": [
        "# Train encoder\n",
        "print(\"----------Train------------\")\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train_epoch(model, CLR_train_loader, CLR_optimizer, CLR_loss_fn, temperature, device, scheduler)\n",
        "    print('Epoch: {}, Loss: {}'.format(epoch, train_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "30be1eb6c9e97206",
      "metadata": {
        "editable": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "id": "30be1eb6c9e97206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd898852-409b-4b28-9156-44d1b3b3da0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Train Classifier------------\n",
            "Classifier - Epoch: 1, Loss: 0.7018762108564377, Accuracy: 83.07666666666667\n",
            "Test - Epoch: 1, Loss: 0.22243525574207307, Accuracy: 95.15\n",
            "Classifier - Epoch: 2, Loss: 0.1990634534597397, Accuracy: 95.57833333333333\n",
            "Test - Epoch: 2, Loss: 0.1575004495024681, Accuracy: 96.58\n",
            "Classifier - Epoch: 3, Loss: 0.15882994296948116, Accuracy: 96.25833333333334\n",
            "Test - Epoch: 3, Loss: 0.1326299097776413, Accuracy: 96.99\n",
            "Classifier - Epoch: 4, Loss: 0.13904957903226217, Accuracy: 96.66666666666667\n",
            "Test - Epoch: 4, Loss: 0.1184900804400444, Accuracy: 97.2\n",
            "Classifier - Epoch: 5, Loss: 0.12611327072381973, Accuracy: 96.87833333333333\n",
            "Test - Epoch: 5, Loss: 0.10897275111675263, Accuracy: 97.26\n",
            "Classifier - Epoch: 6, Loss: 0.11680334549744924, Accuracy: 97.09333333333333\n",
            "Test - Epoch: 6, Loss: 0.10182454489469528, Accuracy: 97.35000000000001\n",
            "Classifier - Epoch: 7, Loss: 0.11040541930596033, Accuracy: 97.09333333333333\n",
            "Test - Epoch: 7, Loss: 0.09694757107496262, Accuracy: 97.35000000000001\n",
            "Classifier - Epoch: 8, Loss: 0.10533152099847794, Accuracy: 97.31\n",
            "Test - Epoch: 8, Loss: 0.09228367927074432, Accuracy: 97.42\n",
            "Classifier - Epoch: 9, Loss: 0.10017307676076889, Accuracy: 97.41166666666666\n",
            "Test - Epoch: 9, Loss: 0.08908319401741027, Accuracy: 97.49\n",
            "Classifier - Epoch: 10, Loss: 0.09680151175260544, Accuracy: 97.42\n",
            "Test - Epoch: 10, Loss: 0.08548072998523712, Accuracy: 97.53\n",
            "Classifier - Epoch: 11, Loss: 0.09323389906485875, Accuracy: 97.53500000000001\n",
            "Test - Epoch: 11, Loss: 0.08327099882960319, Accuracy: 97.54\n",
            "Classifier - Epoch: 12, Loss: 0.09047601370811463, Accuracy: 97.555\n",
            "Test - Epoch: 12, Loss: 0.08045519634485244, Accuracy: 97.64\n",
            "Classifier - Epoch: 13, Loss: 0.08767739133437474, Accuracy: 97.60833333333333\n",
            "Test - Epoch: 13, Loss: 0.07849855739474297, Accuracy: 97.68\n",
            "Classifier - Epoch: 14, Loss: 0.08530145516792934, Accuracy: 97.72666666666666\n",
            "Test - Epoch: 14, Loss: 0.07673685010075569, Accuracy: 97.71\n",
            "Classifier - Epoch: 15, Loss: 0.08339140418767929, Accuracy: 97.72166666666666\n",
            "Test - Epoch: 15, Loss: 0.07531442700028419, Accuracy: 97.72999999999999\n",
            "Classifier - Epoch: 16, Loss: 0.08166920416752498, Accuracy: 97.81666666666666\n",
            "Test - Epoch: 16, Loss: 0.0734819297015667, Accuracy: 97.85000000000001\n",
            "Classifier - Epoch: 17, Loss: 0.07975033756891886, Accuracy: 97.79666666666667\n",
            "Test - Epoch: 17, Loss: 0.07205170549154281, Accuracy: 97.87\n",
            "Classifier - Epoch: 18, Loss: 0.07782139702240626, Accuracy: 97.84333333333333\n",
            "Test - Epoch: 18, Loss: 0.07068932594060898, Accuracy: 97.92999999999999\n",
            "Classifier - Epoch: 19, Loss: 0.07639658636848132, Accuracy: 97.91666666666666\n",
            "Test - Epoch: 19, Loss: 0.06929420323371888, Accuracy: 97.97\n",
            "Classifier - Epoch: 20, Loss: 0.0749087657014529, Accuracy: 97.88833333333334\n",
            "Test - Epoch: 20, Loss: 0.06881419994235038, Accuracy: 97.99\n"
          ]
        }
      ],
      "source": [
        "for param in model.encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Train classifier\n",
        "print(\"------Train Classifier------------\")\n",
        "for epoch in range(1, epochs + 1):\n",
        "    class_loss, class_acc = train_classifier(model, Class_train_loader, Class_optimizer, Class_loss_fn, device)\n",
        "    print('Classifier - Epoch: {}, Loss: {}, Accuracy: {}'.format(epoch, class_loss, class_acc))\n",
        "    test_loss, test_acc = test_epoch(model, test_loader, Class_loss_fn, device)\n",
        "    print('Test - Epoch: {}, Loss: {}, Accuracy: {}'.format(epoch, test_loss, test_acc))\n",
        "\n",
        "utils.plot_tsne(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8e042bcc-5dc0-4a1b-a7d0-e605db88a3ab",
      "metadata": {
        "id": "8e042bcc-5dc0-4a1b-a7d0-e605db88a3ab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}