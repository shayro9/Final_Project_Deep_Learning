{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582590096dbb0597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T00:22:15.531891800Z",
     "start_time": "2025-03-20T00:22:12.983071600Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "582590096dbb0597"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from train import *\n",
    "import utils\n",
    "from model import CLR\n",
    "\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T00:22:16.759007100Z",
     "start_time": "2025-03-20T00:22:16.754002300Z"
    },
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "feature_dim = 128\n",
    "batch_size = 1024\n",
    "epochs = 100\n",
    "\n",
    "# CLR train\n",
    "CLR_lr = 0.6\n",
    "CLR_min_lr = 1e-3\n",
    "CLR_momentum = 0.9\n",
    "CLR_wd = 1e-6\n",
    "temperature = 0.4\n",
    "\n",
    "# Classify train\n",
    "Class_lr = 1e-3\n",
    "Class_wd = 1e-4\n",
    "\n",
    "dataset = \"CIFAR10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314e53d87154dd9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T00:22:17.496677200Z",
     "start_time": "2025-03-20T00:22:17.480662700Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "314e53d87154dd9a",
    "outputId": "dec1dd9b-06a4-4770-ac80-a7cdc2df83b0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb6999b46c39123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T00:22:19.734214600Z",
     "start_time": "2025-03-20T00:22:18.242354800Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "4bb6999b46c39123",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dd6cbfa1-7e43-4444-c1a5-2bc64500b1be"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 170M/170M [00:16<00:00, 10.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"CIFAR10\":\n",
    "    in_ch = 3\n",
    "    CLR_train_data = utils.CIFAR10Pair(root='/datasets/cv_datasets/data', train=True,\n",
    "                                       transform=utils.CIFAR10_train_transform, download=True)\n",
    "    Class_train_data = utils.CIFAR10(root='/datasets/cv_datasets/data', train=True, transform=utils.CIFAR10_test_transform,\n",
    "                                     download=True)\n",
    "    test_data = utils.CIFAR10(root='/datasets/cv_datasets/data', train=False, transform=utils.CIFAR10_test_transform,\n",
    "                              download=True)\n",
    "else:\n",
    "    in_ch = 1\n",
    "    CLR_train_data = utils.MNISTPair(root='./data', train=True,\n",
    "                                     transform=utils.MNIST_train_transform, download=True)\n",
    "    Class_train_data = utils.MNIST(root='./data', train=True, transform=utils.MNIST_test_transform,\n",
    "                                   download=True)\n",
    "    test_data = utils.MNIST(root='./data', train=False, transform=utils.MNIST_test_transform,\n",
    "                            download=True)\n",
    "CLR_train_loader = DataLoader(CLR_train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True,\n",
    "                              drop_last=True)\n",
    "Class_train_loader = DataLoader(Class_train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be5577121678a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T00:22:20.389810300Z",
     "start_time": "2025-03-20T00:22:20.367790300Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "9be5577121678a19"
   },
   "outputs": [],
   "source": [
    "model = CLR(in_ch, feature_dim).to(device)\n",
    "CLR_optimizer = torch.optim.SGD(model.parameters(), CLR_lr, momentum=CLR_momentum, weight_decay=CLR_wd)\n",
    "CLR_loss_fn = utils.NTXentLoss\n",
    "Class_optimizer = torch.optim.SGD(model.classifier.parameters(), lr=Class_lr, momentum=0.9, weight_decay=Class_wd)\n",
    "Class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "warmup = LinearLR(CLR_optimizer, start_factor=1e-4, end_factor=1.0, total_iters=5 * len(CLR_train_loader))\n",
    "\n",
    "cosine = CosineAnnealingLR(CLR_optimizer, T_max=(epochs - 5) * len(CLR_train_loader), eta_min=CLR_min_lr)\n",
    "\n",
    "scheduler = SequentialLR(CLR_optimizer, schedulers=[warmup, cosine], milestones=[5 * len(CLR_train_loader)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaf2ca79791d6540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T00:22:43.600249900Z",
     "start_time": "2025-03-20T00:22:21.159509500Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaf2ca79791d6540",
    "outputId": "33feb541-0ad4-43b5-dfe1-7e539fe37183"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------Train------------\n",
      "Epoch: 1, Loss: 6.32696000734965\n",
      "Epoch: 2, Loss: 5.863157729307811\n",
      "Epoch: 3, Loss: 5.741210212310155\n",
      "Epoch: 4, Loss: 5.669933785994847\n",
      "Epoch: 5, Loss: 5.571065763632457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 6, Loss: 5.504906624555588\n",
      "Epoch: 7, Loss: 5.454383124907811\n",
      "Epoch: 8, Loss: 5.410984883705775\n",
      "Epoch: 9, Loss: 5.386831631263097\n",
      "Epoch: 10, Loss: 5.3558773795763654\n",
      "Epoch: 11, Loss: 5.337905645370483\n",
      "Epoch: 12, Loss: 5.321505566438039\n",
      "Epoch: 13, Loss: 5.3079849779605865\n",
      "Epoch: 14, Loss: 5.298394550879796\n",
      "Epoch: 15, Loss: 5.284863283236821\n",
      "Epoch: 16, Loss: 5.273321598768234\n",
      "Epoch: 17, Loss: 5.26464365919431\n",
      "Epoch: 18, Loss: 5.2531003455321\n",
      "Epoch: 19, Loss: 5.242337177197139\n",
      "Epoch: 20, Loss: 5.232055306434631\n",
      "Epoch: 21, Loss: 5.2245893478393555\n",
      "Epoch: 22, Loss: 5.218439191579819\n",
      "Epoch: 23, Loss: 5.215170582135518\n",
      "Epoch: 24, Loss: 5.2068106432755785\n",
      "Epoch: 25, Loss: 5.201913644870122\n",
      "Epoch: 26, Loss: 5.1985509395599365\n",
      "Epoch: 27, Loss: 5.1916087965170545\n",
      "Epoch: 28, Loss: 5.183945139249166\n",
      "Epoch: 29, Loss: 5.184819589058558\n",
      "Epoch: 30, Loss: 5.175801048676173\n",
      "Epoch: 31, Loss: 5.170028517643611\n",
      "Epoch: 32, Loss: 5.169393986463547\n",
      "Epoch: 33, Loss: 5.164134939511617\n",
      "Epoch: 34, Loss: 5.157798846562703\n",
      "Epoch: 35, Loss: 5.155851284662883\n",
      "Epoch: 36, Loss: 5.155140986045201\n",
      "Epoch: 37, Loss: 5.149030188719432\n",
      "Epoch: 38, Loss: 5.148023913304011\n",
      "Epoch: 39, Loss: 5.14415501554807\n",
      "Epoch: 40, Loss: 5.139513969421387\n",
      "Epoch: 41, Loss: 5.1360199848810835\n",
      "Epoch: 42, Loss: 5.134967605272929\n",
      "Epoch: 43, Loss: 5.126745631297429\n",
      "Epoch: 44, Loss: 5.1289697388807935\n",
      "Epoch: 45, Loss: 5.124832928180695\n",
      "Epoch: 46, Loss: 5.1220731635888415\n",
      "Epoch: 47, Loss: 5.119014273087184\n",
      "Epoch: 48, Loss: 5.120155413945516\n",
      "Epoch: 49, Loss: 5.117535660664241\n",
      "Epoch: 50, Loss: 5.117621997992198\n",
      "Epoch: 51, Loss: 5.110056171814601\n",
      "Epoch: 52, Loss: 5.10794864098231\n",
      "Epoch: 53, Loss: 5.10542909304301\n",
      "Epoch: 54, Loss: 5.101447691520055\n",
      "Epoch: 55, Loss: 5.10545829931895\n",
      "Epoch: 56, Loss: 5.102287292480469\n",
      "Epoch: 57, Loss: 5.092897872130076\n",
      "Epoch: 58, Loss: 5.092224657535553\n",
      "Epoch: 59, Loss: 5.0958069662253065\n",
      "Epoch: 60, Loss: 5.088678667942683\n",
      "Epoch: 61, Loss: 5.0871606568495435\n",
      "Epoch: 62, Loss: 5.085480213165283\n",
      "Epoch: 63, Loss: 5.084452261527379\n",
      "Epoch: 64, Loss: 5.083137472470601\n",
      "Epoch: 65, Loss: 5.08373365799586\n",
      "Epoch: 66, Loss: 5.080607533454895\n",
      "Epoch: 67, Loss: 5.077278792858124\n",
      "Epoch: 68, Loss: 5.07657112677892\n",
      "Epoch: 69, Loss: 5.072092552979787\n",
      "Epoch: 70, Loss: 5.073731084664662\n",
      "Epoch: 71, Loss: 5.070666352907817\n",
      "Epoch: 72, Loss: 5.069049110015233\n",
      "Epoch: 73, Loss: 5.065804680188497\n",
      "Epoch: 74, Loss: 5.066895951827367\n",
      "Epoch: 75, Loss: 5.065065066019694\n",
      "Epoch: 76, Loss: 5.067962030569713\n",
      "Epoch: 77, Loss: 5.068527817726135\n",
      "Epoch: 78, Loss: 5.062960267066956\n",
      "Epoch: 79, Loss: 5.065584599971771\n",
      "Epoch: 80, Loss: 5.06033331155777\n",
      "Epoch: 81, Loss: 5.060941497484843\n",
      "Epoch: 82, Loss: 5.058023363351822\n",
      "Epoch: 83, Loss: 5.058555752038956\n",
      "Epoch: 84, Loss: 5.056219786405563\n",
      "Epoch: 85, Loss: 5.0575765868028\n",
      "Epoch: 86, Loss: 5.058685471614202\n",
      "Epoch: 87, Loss: 5.053394536177318\n",
      "Epoch: 88, Loss: 5.056792249282201\n",
      "Epoch: 89, Loss: 5.051344076792399\n",
      "Epoch: 90, Loss: 5.055207798878352\n",
      "Epoch: 91, Loss: 5.051966468493144\n",
      "Epoch: 92, Loss: 5.048584858576457\n",
      "Epoch: 93, Loss: 5.053426792224248\n",
      "Epoch: 94, Loss: 5.049528529246648\n",
      "Epoch: 95, Loss: 5.050595819950104\n",
      "Epoch: 96, Loss: 5.050291866064072\n",
      "Epoch: 97, Loss: 5.053368240594864\n",
      "Epoch: 98, Loss: 5.055499782164891\n",
      "Epoch: 99, Loss: 5.052044749259949\n",
      "Epoch: 100, Loss: 5.044937252998352\n"
     ]
    }
   ],
   "source": [
    "# Train encoder\n",
    "print(\"----------Train------------\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_epoch(model, CLR_train_loader, CLR_optimizer, CLR_loss_fn, temperature, device, scheduler)\n",
    "    print('Epoch: {}, Loss: {}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30be1eb6c9e97206",
   "metadata": {
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [],
    "id": "30be1eb6c9e97206",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1cae7a48-caf8-464c-9f33-c58d58f69ae6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------Train Classifier------------\n",
      "Classifier - Epoch: 1, Loss: 1.320813939037323, Accuracy: 57.550000000000004\n",
      "Test - Epoch: 1, Loss: 0.8702166150093079, Accuracy: 71.41999999999999\n",
      "Classifier - Epoch: 2, Loss: 0.8117879318618775, Accuracy: 72.602\n",
      "Test - Epoch: 2, Loss: 0.7840889302253723, Accuracy: 73.21\n",
      "Classifier - Epoch: 3, Loss: 0.753658737449646, Accuracy: 74.19200000000001\n",
      "Test - Epoch: 3, Loss: 0.7475288650512696, Accuracy: 74.16\n",
      "Classifier - Epoch: 4, Loss: 0.7224311487007141, Accuracy: 75.136\n",
      "Test - Epoch: 4, Loss: 0.7246967570304871, Accuracy: 74.96000000000001\n",
      "Classifier - Epoch: 5, Loss: 0.7025328971672058, Accuracy: 75.652\n",
      "Test - Epoch: 5, Loss: 0.7098075491905212, Accuracy: 75.32\n",
      "Classifier - Epoch: 6, Loss: 0.6885229446983337, Accuracy: 75.972\n",
      "Test - Epoch: 6, Loss: 0.6981242444992065, Accuracy: 75.46000000000001\n",
      "Classifier - Epoch: 7, Loss: 0.6770308042526245, Accuracy: 76.348\n",
      "Test - Epoch: 7, Loss: 0.6883173439979553, Accuracy: 75.9\n",
      "Classifier - Epoch: 8, Loss: 0.6664854591941833, Accuracy: 76.666\n",
      "Test - Epoch: 8, Loss: 0.6801877820014953, Accuracy: 76.11\n",
      "Classifier - Epoch: 9, Loss: 0.6589564897346497, Accuracy: 76.88199999999999\n",
      "Test - Epoch: 9, Loss: 0.6735916078567505, Accuracy: 76.23\n",
      "Classifier - Epoch: 10, Loss: 0.6529543654632568, Accuracy: 77.022\n",
      "Test - Epoch: 10, Loss: 0.6686817767143249, Accuracy: 76.4\n",
      "Classifier - Epoch: 11, Loss: 0.645556743068695, Accuracy: 77.358\n",
      "Test - Epoch: 11, Loss: 0.6625471002578736, Accuracy: 76.57000000000001\n",
      "Classifier - Epoch: 12, Loss: 0.6401754699897766, Accuracy: 77.56\n",
      "Test - Epoch: 12, Loss: 0.6583336418151855, Accuracy: 76.69\n",
      "Classifier - Epoch: 13, Loss: 0.6345193657302857, Accuracy: 77.50200000000001\n",
      "Test - Epoch: 13, Loss: 0.6547154439926147, Accuracy: 76.75\n",
      "Classifier - Epoch: 14, Loss: 0.6305183163642883, Accuracy: 77.762\n",
      "Test - Epoch: 14, Loss: 0.6505658975601196, Accuracy: 76.85\n",
      "Classifier - Epoch: 15, Loss: 0.6264143322944641, Accuracy: 77.91799999999999\n",
      "Test - Epoch: 15, Loss: 0.6472179837226868, Accuracy: 77.25\n",
      "Classifier - Epoch: 16, Loss: 0.6217055723953248, Accuracy: 77.964\n",
      "Test - Epoch: 16, Loss: 0.6437982417106628, Accuracy: 77.13\n",
      "Classifier - Epoch: 17, Loss: 0.6190456594276428, Accuracy: 78.116\n",
      "Test - Epoch: 17, Loss: 0.640799381351471, Accuracy: 77.27000000000001\n",
      "Classifier - Epoch: 18, Loss: 0.6151707601737976, Accuracy: 78.286\n",
      "Test - Epoch: 18, Loss: 0.6380834577560425, Accuracy: 77.38000000000001\n",
      "Classifier - Epoch: 19, Loss: 0.6122437063217163, Accuracy: 78.468\n",
      "Test - Epoch: 19, Loss: 0.6356310629844666, Accuracy: 77.51\n",
      "Classifier - Epoch: 20, Loss: 0.6090282955741882, Accuracy: 78.574\n",
      "Test - Epoch: 20, Loss: 0.6334208337783813, Accuracy: 77.57\n",
      "Classifier - Epoch: 21, Loss: 0.605494083404541, Accuracy: 78.714\n",
      "Test - Epoch: 21, Loss: 0.6309200823783875, Accuracy: 77.53999999999999\n",
      "Classifier - Epoch: 22, Loss: 0.6033954058456421, Accuracy: 78.8\n",
      "Test - Epoch: 22, Loss: 0.6281534929275513, Accuracy: 77.75\n",
      "Classifier - Epoch: 23, Loss: 0.5996301523590087, Accuracy: 78.85\n",
      "Test - Epoch: 23, Loss: 0.6259066118240356, Accuracy: 77.74\n",
      "Classifier - Epoch: 24, Loss: 0.5981288956069947, Accuracy: 78.984\n",
      "Test - Epoch: 24, Loss: 0.6244265057563781, Accuracy: 77.92999999999999\n",
      "Classifier - Epoch: 25, Loss: 0.5947018314743042, Accuracy: 79.022\n",
      "Test - Epoch: 25, Loss: 0.6220367827415466, Accuracy: 77.92999999999999\n",
      "Classifier - Epoch: 26, Loss: 0.5930594493484497, Accuracy: 79.034\n",
      "Test - Epoch: 26, Loss: 0.620187772846222, Accuracy: 78.10000000000001\n",
      "Classifier - Epoch: 27, Loss: 0.5908686786651611, Accuracy: 79.258\n",
      "Test - Epoch: 27, Loss: 0.6191247328758239, Accuracy: 78.22\n",
      "Classifier - Epoch: 28, Loss: 0.589109577331543, Accuracy: 79.034\n",
      "Test - Epoch: 28, Loss: 0.6171317648887634, Accuracy: 78.10000000000001\n",
      "Classifier - Epoch: 29, Loss: 0.5870280281448365, Accuracy: 79.132\n",
      "Test - Epoch: 29, Loss: 0.6148788290023803, Accuracy: 78.19\n",
      "Classifier - Epoch: 30, Loss: 0.5832135821533203, Accuracy: 79.448\n",
      "Test - Epoch: 30, Loss: 0.6133092053413391, Accuracy: 78.28\n",
      "Classifier - Epoch: 31, Loss: 0.583487038898468, Accuracy: 79.432\n",
      "Test - Epoch: 31, Loss: 0.6119652283668519, Accuracy: 78.25\n",
      "Classifier - Epoch: 32, Loss: 0.5792359350585937, Accuracy: 79.508\n",
      "Test - Epoch: 32, Loss: 0.6108172902107238, Accuracy: 78.28\n",
      "Classifier - Epoch: 33, Loss: 0.578067989063263, Accuracy: 79.57\n",
      "Test - Epoch: 33, Loss: 0.609377061367035, Accuracy: 78.36999999999999\n",
      "Classifier - Epoch: 34, Loss: 0.576633318786621, Accuracy: 79.664\n",
      "Test - Epoch: 34, Loss: 0.6077915843963623, Accuracy: 78.41\n",
      "Classifier - Epoch: 35, Loss: 0.5741338089370728, Accuracy: 79.67999999999999\n",
      "Test - Epoch: 35, Loss: 0.6059089150428772, Accuracy: 78.5\n",
      "Classifier - Epoch: 36, Loss: 0.5704350542068481, Accuracy: 79.93599999999999\n",
      "Test - Epoch: 36, Loss: 0.606006086063385, Accuracy: 78.58000000000001\n",
      "Classifier - Epoch: 37, Loss: 0.5709178275871277, Accuracy: 79.732\n",
      "Test - Epoch: 37, Loss: 0.6035487729072571, Accuracy: 78.47\n",
      "Classifier - Epoch: 38, Loss: 0.5694273372650146, Accuracy: 79.798\n",
      "Test - Epoch: 38, Loss: 0.6023833993911744, Accuracy: 78.72\n",
      "Classifier - Epoch: 39, Loss: 0.5676718648338318, Accuracy: 79.86999999999999\n",
      "Test - Epoch: 39, Loss: 0.6009508619308471, Accuracy: 78.72\n",
      "Classifier - Epoch: 40, Loss: 0.5657339319038391, Accuracy: 79.96600000000001\n",
      "Test - Epoch: 40, Loss: 0.5997007884979249, Accuracy: 78.78\n",
      "Classifier - Epoch: 41, Loss: 0.5639162900161743, Accuracy: 80.012\n",
      "Test - Epoch: 41, Loss: 0.5985917163848877, Accuracy: 78.74\n",
      "Classifier - Epoch: 42, Loss: 0.5635710541915894, Accuracy: 80.12\n",
      "Test - Epoch: 42, Loss: 0.5975303963661194, Accuracy: 78.77\n",
      "Classifier - Epoch: 43, Loss: 0.5610321218299865, Accuracy: 80.19\n",
      "Test - Epoch: 43, Loss: 0.5961257940292358, Accuracy: 78.8\n",
      "Classifier - Epoch: 44, Loss: 0.5604655973625183, Accuracy: 80.108\n",
      "Test - Epoch: 44, Loss: 0.5960119965553283, Accuracy: 78.8\n",
      "Classifier - Epoch: 45, Loss: 0.5596353013038635, Accuracy: 80.24\n",
      "Test - Epoch: 45, Loss: 0.5937095245361328, Accuracy: 78.82000000000001\n",
      "Classifier - Epoch: 46, Loss: 0.5561137743759156, Accuracy: 80.354\n",
      "Test - Epoch: 46, Loss: 0.5934401700973511, Accuracy: 78.88\n",
      "Classifier - Epoch: 47, Loss: 0.5561230418395996, Accuracy: 80.296\n",
      "Test - Epoch: 47, Loss: 0.5919431450843811, Accuracy: 78.92\n",
      "Classifier - Epoch: 48, Loss: 0.5536960641288757, Accuracy: 80.298\n",
      "Test - Epoch: 48, Loss: 0.5911862902641296, Accuracy: 78.95\n",
      "Classifier - Epoch: 49, Loss: 0.551373372554779, Accuracy: 80.46799999999999\n",
      "Test - Epoch: 49, Loss: 0.5901218132972718, Accuracy: 78.97\n",
      "Classifier - Epoch: 50, Loss: 0.550950430393219, Accuracy: 80.5\n",
      "Test - Epoch: 50, Loss: 0.588542006111145, Accuracy: 79.03999999999999\n",
      "Classifier - Epoch: 51, Loss: 0.5498539047431946, Accuracy: 80.49\n",
      "Test - Epoch: 51, Loss: 0.5883354444503784, Accuracy: 79.09\n",
      "Classifier - Epoch: 52, Loss: 0.5491016511344909, Accuracy: 80.582\n",
      "Test - Epoch: 52, Loss: 0.5869732791900635, Accuracy: 79.03999999999999\n",
      "Classifier - Epoch: 53, Loss: 0.547232961063385, Accuracy: 80.65\n",
      "Test - Epoch: 53, Loss: 0.5863731557846069, Accuracy: 79.13\n",
      "Classifier - Epoch: 54, Loss: 0.5446111023712158, Accuracy: 80.57600000000001\n",
      "Test - Epoch: 54, Loss: 0.5852818376541138, Accuracy: 79.2\n",
      "Classifier - Epoch: 55, Loss: 0.5441425555610657, Accuracy: 80.738\n",
      "Test - Epoch: 55, Loss: 0.5841004160881043, Accuracy: 79.16\n",
      "Classifier - Epoch: 56, Loss: 0.5425389208602905, Accuracy: 80.752\n",
      "Test - Epoch: 56, Loss: 0.583718593120575, Accuracy: 79.23\n",
      "Classifier - Epoch: 57, Loss: 0.5415344754981994, Accuracy: 80.708\n",
      "Test - Epoch: 57, Loss: 0.582805037021637, Accuracy: 79.17999999999999\n",
      "Classifier - Epoch: 58, Loss: 0.5396013509368897, Accuracy: 80.82000000000001\n",
      "Test - Epoch: 58, Loss: 0.582037761592865, Accuracy: 79.17\n",
      "Classifier - Epoch: 59, Loss: 0.5378762327766419, Accuracy: 81.036\n",
      "Test - Epoch: 59, Loss: 0.5808810844421387, Accuracy: 79.33\n",
      "Classifier - Epoch: 60, Loss: 0.5373134419250488, Accuracy: 80.906\n",
      "Test - Epoch: 60, Loss: 0.5801059610366821, Accuracy: 79.36999999999999\n",
      "Classifier - Epoch: 61, Loss: 0.5378415627479554, Accuracy: 80.982\n",
      "Test - Epoch: 61, Loss: 0.5790968941688538, Accuracy: 79.45\n",
      "Classifier - Epoch: 62, Loss: 0.5349820179748536, Accuracy: 81.03200000000001\n",
      "Test - Epoch: 62, Loss: 0.5782765911102294, Accuracy: 79.42\n",
      "Classifier - Epoch: 63, Loss: 0.5340922409057617, Accuracy: 80.974\n",
      "Test - Epoch: 63, Loss: 0.5773178235054016, Accuracy: 79.4\n",
      "Classifier - Epoch: 64, Loss: 0.5321502387619018, Accuracy: 81.192\n",
      "Test - Epoch: 64, Loss: 0.5769990189552308, Accuracy: 79.47\n",
      "Classifier - Epoch: 65, Loss: 0.5313696036338806, Accuracy: 81.15\n",
      "Test - Epoch: 65, Loss: 0.5757204555511475, Accuracy: 79.38\n",
      "Classifier - Epoch: 66, Loss: 0.53072192237854, Accuracy: 81.196\n",
      "Test - Epoch: 66, Loss: 0.5753974649429321, Accuracy: 79.54\n",
      "Classifier - Epoch: 67, Loss: 0.5296203462028504, Accuracy: 81.178\n",
      "Test - Epoch: 67, Loss: 0.5744863175392151, Accuracy: 79.46\n",
      "Classifier - Epoch: 68, Loss: 0.52698338722229, Accuracy: 81.414\n",
      "Test - Epoch: 68, Loss: 0.5741772513389587, Accuracy: 79.52\n",
      "Classifier - Epoch: 69, Loss: 0.5260410457801818, Accuracy: 81.33399999999999\n",
      "Test - Epoch: 69, Loss: 0.5733284172058105, Accuracy: 79.54\n",
      "Classifier - Epoch: 70, Loss: 0.5261698982620239, Accuracy: 81.386\n",
      "Test - Epoch: 70, Loss: 0.5721145373344422, Accuracy: 79.62\n",
      "Classifier - Epoch: 71, Loss: 0.5242472352790832, Accuracy: 81.56\n",
      "Test - Epoch: 71, Loss: 0.5712188036918641, Accuracy: 79.57\n",
      "Classifier - Epoch: 72, Loss: 0.5240426099777221, Accuracy: 81.42399999999999\n",
      "Test - Epoch: 72, Loss: 0.5708589635848998, Accuracy: 79.55\n",
      "Classifier - Epoch: 73, Loss: 0.5224388881874085, Accuracy: 81.512\n",
      "Test - Epoch: 73, Loss: 0.5699094741821289, Accuracy: 79.75999999999999\n",
      "Classifier - Epoch: 74, Loss: 0.5217770962524414, Accuracy: 81.562\n",
      "Test - Epoch: 74, Loss: 0.5696501894950867, Accuracy: 79.66\n",
      "Classifier - Epoch: 75, Loss: 0.5199379129981995, Accuracy: 81.608\n",
      "Test - Epoch: 75, Loss: 0.568570555305481, Accuracy: 79.80000000000001\n",
      "Classifier - Epoch: 76, Loss: 0.5195130106639863, Accuracy: 81.57799999999999\n",
      "Test - Epoch: 76, Loss: 0.5679983645439148, Accuracy: 79.67\n",
      "Classifier - Epoch: 77, Loss: 0.5184161988544465, Accuracy: 81.672\n",
      "Test - Epoch: 77, Loss: 0.56745425157547, Accuracy: 79.60000000000001\n",
      "Classifier - Epoch: 78, Loss: 0.5172823353195191, Accuracy: 81.684\n",
      "Test - Epoch: 78, Loss: 0.5668366535186767, Accuracy: 79.82000000000001\n",
      "Classifier - Epoch: 79, Loss: 0.5151067011070252, Accuracy: 81.892\n",
      "Test - Epoch: 79, Loss: 0.5663595379829407, Accuracy: 79.78\n",
      "Classifier - Epoch: 80, Loss: 0.5167648709487915, Accuracy: 81.83399999999999\n",
      "Test - Epoch: 80, Loss: 0.5654942433357238, Accuracy: 79.75999999999999\n",
      "Classifier - Epoch: 81, Loss: 0.5135987110328675, Accuracy: 81.836\n",
      "Test - Epoch: 81, Loss: 0.5647031694412231, Accuracy: 79.81\n",
      "Classifier - Epoch: 82, Loss: 0.5137555912399292, Accuracy: 81.75200000000001\n",
      "Test - Epoch: 82, Loss: 0.5646606479644776, Accuracy: 79.94\n",
      "Classifier - Epoch: 83, Loss: 0.5127606733703614, Accuracy: 81.904\n",
      "Test - Epoch: 83, Loss: 0.5637964351654052, Accuracy: 79.91\n",
      "Classifier - Epoch: 84, Loss: 0.5116203428268432, Accuracy: 81.868\n",
      "Test - Epoch: 84, Loss: 0.5632075178146362, Accuracy: 79.86999999999999\n",
      "Classifier - Epoch: 85, Loss: 0.5097324570941925, Accuracy: 82.00800000000001\n",
      "Test - Epoch: 85, Loss: 0.5626031423568726, Accuracy: 79.75\n",
      "Classifier - Epoch: 86, Loss: 0.5090559433364868, Accuracy: 81.82199999999999\n",
      "Test - Epoch: 86, Loss: 0.5621796323776245, Accuracy: 79.91\n",
      "Classifier - Epoch: 87, Loss: 0.5073986016845703, Accuracy: 82.052\n",
      "Test - Epoch: 87, Loss: 0.5619149666786194, Accuracy: 79.85\n",
      "Classifier - Epoch: 88, Loss: 0.5070370014381409, Accuracy: 82.018\n",
      "Test - Epoch: 88, Loss: 0.5608074827194214, Accuracy: 79.92\n",
      "Classifier - Epoch: 89, Loss: 0.5051988115310669, Accuracy: 82.084\n",
      "Test - Epoch: 89, Loss: 0.5603222659111023, Accuracy: 79.99000000000001\n",
      "Classifier - Epoch: 90, Loss: 0.5034764733314514, Accuracy: 82.092\n",
      "Test - Epoch: 90, Loss: 0.5594148210525512, Accuracy: 79.97999999999999\n",
      "Classifier - Epoch: 91, Loss: 0.5036908896636962, Accuracy: 82.13000000000001\n",
      "Test - Epoch: 91, Loss: 0.5593072464942932, Accuracy: 79.97\n",
      "Classifier - Epoch: 92, Loss: 0.5037579692077637, Accuracy: 82.174\n",
      "Test - Epoch: 92, Loss: 0.5587879549980164, Accuracy: 80.06\n",
      "Classifier - Epoch: 93, Loss: 0.5016817359733582, Accuracy: 82.26400000000001\n",
      "Test - Epoch: 93, Loss: 0.5576134708404541, Accuracy: 80.04\n",
      "Classifier - Epoch: 94, Loss: 0.5010647678947449, Accuracy: 82.284\n",
      "Test - Epoch: 94, Loss: 0.5569233675956726, Accuracy: 80.03\n",
      "Classifier - Epoch: 95, Loss: 0.49978611347198487, Accuracy: 82.336\n",
      "Test - Epoch: 95, Loss: 0.556764301109314, Accuracy: 80.06\n",
      "Classifier - Epoch: 96, Loss: 0.49741627270698546, Accuracy: 82.492\n",
      "Test - Epoch: 96, Loss: 0.5557302061080933, Accuracy: 80.07\n",
      "Classifier - Epoch: 97, Loss: 0.49850867857933046, Accuracy: 82.37\n",
      "Test - Epoch: 97, Loss: 0.5559542617797851, Accuracy: 80.12\n",
      "Classifier - Epoch: 98, Loss: 0.49669902609825134, Accuracy: 82.38\n",
      "Test - Epoch: 98, Loss: 0.5552710384368896, Accuracy: 80.08999999999999\n",
      "Classifier - Epoch: 99, Loss: 0.4967101201248169, Accuracy: 82.43599999999999\n",
      "Test - Epoch: 99, Loss: 0.5553340987205505, Accuracy: 80.17999999999999\n",
      "Classifier - Epoch: 100, Loss: 0.4956039953327179, Accuracy: 82.44\n",
      "Test - Epoch: 100, Loss: 0.5537173721313476, Accuracy: 80.25\n"
     ]
    }
   ],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Train classifier\n",
    "print(\"------Train Classifier------------\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    class_loss, class_acc = train_classifier(model, Class_train_loader, Class_optimizer, Class_loss_fn, device)\n",
    "    print('Classifier - Epoch: {}, Loss: {}, Accuracy: {}'.format(epoch, class_loss, class_acc))\n",
    "    test_loss, test_acc = test_epoch(model, test_loader, Class_loss_fn, device)\n",
    "    print('Test - Epoch: {}, Loss: {}, Accuracy: {}'.format(epoch, test_loss, test_acc))\n",
    "\n",
    "utils.plot_tsne(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e042bcc-5dc0-4a1b-a7d0-e605db88a3ab",
   "metadata": {
    "id": "8e042bcc-5dc0-4a1b-a7d0-e605db88a3ab"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
